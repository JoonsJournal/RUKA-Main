#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
WebCam Teleoperator - MediaPipe ê¸°ë°˜ RUKA ë¡œë´‡ ì† ì›ê²©ì¡°ì • (ìµœì í™” ë²„ì „)

ì´ ëª¨ë“ˆì€ ì›¹ìº ê³¼ MediaPipeë¥¼ ì‚¬ìš©í•˜ì—¬ RUKA ë¡œë´‡ ì†ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì œì–´í•©ë‹ˆë‹¤.

ì£¼ìš” ìµœì í™”:
1. MediaPipe Lite ëª¨ë¸ ì‚¬ìš© (modelComplexity=0)
2. ë‚®ì€ í•´ìƒë„ë¡œ ë¹ ë¥¸ ì²˜ë¦¬ (640x480)
3. ê°œì„ ëœ íƒ€ì´ë¨¸ (sleep ê¸°ë°˜)
4. í”„ë ˆì„ ìŠ¤í‚µ ì§€ì›
5. ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

ì‘ì„±ì: ì´ë™ì¤€
ë²„ì „: 2.0 (ìµœì í™”)
"""

# =============================================================================
# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# =============================================================================

from copy import deepcopy as copy
import cv2
import numpy as np
import time
from scipy.spatial.transform import Rotation
from collections import deque

from HandTrackingModule import HandDetector
from ruka_hand.control.operator import RUKAOperator
from ruka_hand.utils.constants import *
from ruka_hand.utils.vectorops import *

# =============================================================================
# ìµœì í™”ëœ íƒ€ì´ë¨¸ í´ë˜ìŠ¤
# =============================================================================

class OptimizedTimer:
    """CPU íš¨ìœ¨ì ì¸ ì£¼íŒŒìˆ˜ íƒ€ì´ë¨¸"""
    
    def __init__(self, frequency):
        self.target_period = 1.0 / frequency
        self.start_time = 0
        self._fps_history = deque(maxlen=30)
    
    def start_loop(self):
        self.start_time = time.perf_counter()
    
    def end_loop(self):
        elapsed = time.perf_counter() - self.start_time
        self._fps_history.append(1.0 / elapsed if elapsed > 0 else 0)
        
        sleep_time = self.target_period - elapsed
        
        if sleep_time > 0.001:  # 1ms ì´ìƒì¼ ë•Œë§Œ sleep
            time.sleep(sleep_time * 0.9)  # 90% sleep
            # ë‚˜ë¨¸ì§€ ì •ë°€ ëŒ€ê¸°
            while time.perf_counter() - self.start_time < self.target_period:
                pass
    
    @property
    def actual_fps(self):
        """ì‹¤ì œ FPS ë°˜í™˜"""
        if self._fps_history:
            return sum(self._fps_history) / len(self._fps_history)
        return 0
    
    @property
    def loop_time_ms(self):
        """ë£¨í”„ ì‹œê°„ (ms)"""
        return (time.perf_counter() - self.start_time) * 1000

# =============================================================================
# MediaPipe ëœë“œë§ˆí¬ ë§¤í•‘
# =============================================================================

MEDIAPIPE_FINGER_INDICES = {
    "thumb": [0, 1, 2, 3, 4],
    "index": [0, 5, 6, 7, 8],
    "middle": [0, 9, 10, 11, 12],
    "ring": [0, 13, 14, 15, 16],
    "pinky": [0, 17, 18, 19, 20],
}

# =============================================================================
# WebCamTeleoperator í´ë˜ìŠ¤ (ìµœì í™”)
# =============================================================================

class WebCamTeleoperator:
    """
    ì›¹ìº  ê¸°ë°˜ RUKA ë¡œë´‡ ì† ì›ê²©ì¡°ì • í´ë˜ìŠ¤ (ìµœì í™” ë²„ì „)
    
    ìµœì í™” í¬ì¸íŠ¸:
    - MediaPipe Lite ëª¨ë¸ (modelComplexity=0)
    - 640x480 í•´ìƒë„
    - í”„ë ˆì„ ë²„í¼ ìµœì†Œí™”
    - CPU íš¨ìœ¨ì  íƒ€ì´ë¨¸
    - í”„ë ˆì„ ìŠ¤í‚µ ì§€ì›
    """

    def __init__(
        self,
        camera_id=0,
        frequency=20,                   # ğŸ”§ 30â†’20 (í˜„ì‹¤ì  ëª©í‘œ)
        moving_average_limit=5,         # ğŸ”§ 10â†’5 (ì§€ì—° ê°ì†Œ)
        hands=["left", "right"],
        detection_confidence=0.5,       # ğŸ”§ 0.7â†’0.5 (ì†ë„ í–¥ìƒ)
        tracking_confidence=0.5,        # ğŸ”§ 0.7â†’0.5
        debug=False,
        # ğŸ†• ìµœì í™” íŒŒë¼ë¯¸í„°
        resolution=(640, 480),          # ğŸ”§ ì €í•´ìƒë„
        model_complexity=0,             # ğŸ”§ Lite ëª¨ë¸
        skip_frames=0,                  # ğŸ†• í”„ë ˆì„ ìŠ¤í‚µ (0=ì—†ìŒ)
    ):
        """
        WebCamTeleoperator ì´ˆê¸°í™” (ìµœì í™” ë²„ì „)
        
        Parameters:
        -----------
        camera_id : int
            ì›¹ìº  ID (ê¸°ë³¸ê°’: 0)
        frequency : int
            ì œì–´ ì£¼íŒŒìˆ˜ (Hz) - 20Hz ê¶Œì¥
        moving_average_limit : int
            ì´ë™í‰ê·  í•„í„° í¬ê¸° - 5 ê¶Œì¥
        hands : list
            ì œì–´í•  ì† ["left", "right"]
        detection_confidence : float
            ì† ê²€ì¶œ ì‹ ë¢°ë„ - 0.5 ê¶Œì¥ (ì†ë„â†‘)
        tracking_confidence : float
            ì† ì¶”ì  ì‹ ë¢°ë„ - 0.5 ê¶Œì¥ (ì†ë„â†‘)
        debug : bool
            ë””ë²„ê·¸ ëª¨ë“œ (ì„±ëŠ¥ ì €í•˜ ì£¼ì˜!)
        resolution : tuple
            ì›¹ìº  í•´ìƒë„ - (640, 480) ê¶Œì¥
        model_complexity : int
            MediaPipe ëª¨ë¸ ë³µì¡ë„ (0=Lite, 1=Full)
        skip_frames : int
            í”„ë ˆì„ ìŠ¤í‚µ ìˆ˜ (0=ìŠ¤í‚µ ì—†ìŒ)
        """
        
        self.debug = debug
        self.frequency = frequency
        self.skip_frames = skip_frames
        self.frame_counter = 0
        
        # ğŸ”§ ìµœì í™”ëœ íƒ€ì´ë¨¸
        self.timer = OptimizedTimer(frequency)
        
        # ğŸ”§ ì›¹ìº  ìµœì í™” ì„¤ì •
        print(f"[INFO] ì›¹ìº  ì´ˆê¸°í™” ì¤‘... (ì¹´ë©”ë¼ ID: {camera_id})")
        self.cap = cv2.VideoCapture(camera_id)
        
        if not self.cap.isOpened():
            raise RuntimeError(f"ì›¹ìº  ID {camera_id}ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")
        
        # ğŸ”§ í•´ìƒë„ ì„¤ì • (ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„)
        self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, resolution[0])
        self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, resolution[1])
        self.cap.set(cv2.CAP_PROP_FPS, 60)
        
        # ğŸ†• ë²„í¼ ìµœì†Œí™” (ì§€ì—° ê°ì†Œ)
        self.cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)
        
        # ì‹¤ì œ ì ìš©ëœ ì„¤ì • í™•ì¸
        actual_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))
        actual_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
        actual_fps = int(self.cap.get(cv2.CAP_PROP_FPS))
        
        print(f"  âœ“ ì›¹ìº  í•´ìƒë„: {actual_width}x{actual_height}")
        print(f"  âœ“ ì›¹ìº  FPS: {actual_fps}")
        
        # ğŸ”§ MediaPipe Lite ëª¨ë¸ ì‚¬ìš©
        self.detector = HandDetector(
            staticMode=False,
            maxHands=2,
            modelComplexity=model_complexity,  # ğŸ”§ 0=Lite (ë¹ ë¦„!)
            detectionCon=detection_confidence,
            minTrackCon=tracking_confidence
        )
        print(f"  âœ“ MediaPipe (complexity={model_complexity}) ì´ˆê¸°í™” ì™„ë£Œ")
        
        # ì´ë™í‰ê·  í•„í„°
        self.moving_average_limit = moving_average_limit
        self.coord_moving_average_queues = {"left": [], "right": []}
        
        # ì œì–´í•  ì†
        self.hand_names = hands
        self.hands = {}
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self._timing_stats = {
            'webcam': deque(maxlen=30),
            'mediapipe': deque(maxlen=30),
            'transform': deque(maxlen=30),
            'robot': deque(maxlen=30),
        }
        
        print("=" * 60)
        print("WebCam Teleoperator ì´ˆê¸°í™” ì™„ë£Œ (ìµœì í™” ë²„ì „)")
        print(f"  - í•´ìƒë„: {resolution[0]}x{resolution[1]}")
        print(f"  - ëª¨ë¸: {'Lite' if model_complexity == 0 else 'Full'}")
        print(f"  - ëª©í‘œ ì£¼íŒŒìˆ˜: {frequency} Hz")
        print(f"  - ì´ë™í‰ê· : {moving_average_limit}")
        print(f"  - í”„ë ˆì„ ìŠ¤í‚µ: {skip_frames}")
        print("=" * 60)

    def _init_hands(self):
        """RUKAOperator ì´ˆê¸°í™”"""
        print("\n[INFO] ë¡œë´‡ ì† ì´ˆê¸°í™” ì¤‘...")
        
        for hand_name in self.hand_names:
            try:
                self.hands[hand_name] = RUKAOperator(
                    hand_type=hand_name,
                    moving_average_limit=3,  # ğŸ”§ 5â†’3 (ë°˜ì‘ ì†ë„â†‘)
                )
                print(f"  âœ“ {hand_name.upper()} ë¡œë´‡ ì† ì´ˆê¸°í™” ì™„ë£Œ")
            except Exception as e:
                print(f"  âœ— {hand_name.upper()} ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        print("=" * 60)

    def _mediapipe_to_finger_keypoints(self, lmList):
        """MediaPipe 21ê°œ ëœë“œë§ˆí¬ë¥¼ (5, 5, 3) í˜•íƒœë¡œ ë³€í™˜"""
        keypoints = np.zeros((5, 5, 3))
        finger_names = ["thumb", "index", "middle", "ring", "pinky"]
        
        for finger_idx, finger_name in enumerate(finger_names):
            indices = MEDIAPIPE_FINGER_INDICES[finger_name]
            for joint_idx, mp_idx in enumerate(indices):
                if mp_idx < len(lmList):
                    keypoints[finger_idx, joint_idx] = lmList[mp_idx][:3]
        
        return keypoints

    def _translate_coords(self, hand_coords):
        """ì†ëª©ì„ ì›ì ìœ¼ë¡œ í•˜ëŠ” ìƒëŒ€ ì¢Œí‘œê³„ë¡œ ë³€í™˜"""
        wrist = hand_coords[0, 0]
        translated = copy(hand_coords)
        for finger_idx in range(5):
            translated[finger_idx] = translated[finger_idx] - wrist
        return translated

    def _get_hand_dir_frame(self, origin_coord, index_knuckle_coord, pinky_knuckle_coord, hand_name):
        """ì† ë°©í–¥ í”„ë ˆì„ ê³„ì‚°"""
        if hand_name == "left":
            palm_normal = normalize_vector(
                np.cross(index_knuckle_coord, pinky_knuckle_coord)
            )
        else:
            palm_normal = normalize_vector(
                np.cross(pinky_knuckle_coord, index_knuckle_coord)
            )
        
        palm_direction = normalize_vector(
            index_knuckle_coord + pinky_knuckle_coord
        )
        
        if hand_name == "left":
            cross_product = normalize_vector(
                index_knuckle_coord - pinky_knuckle_coord
            )
        else:
            cross_product = normalize_vector(
                pinky_knuckle_coord - index_knuckle_coord
            )
        
        return [origin_coord, cross_product, palm_normal, palm_direction]

    def transform_keypoints(self, hand_coords, hand_name):
        """í‚¤í¬ì¸íŠ¸ ì¢Œí‘œê³„ ë³€í™˜"""
        translated_coords = self._translate_coords(hand_coords)
        
        wrist_pos = hand_coords[0, 0]
        index_knuckle = translated_coords[1, 1]
        pinky_knuckle = translated_coords[4, 1]
        
        hand_dir_frame = self._get_hand_dir_frame(
            wrist_pos, index_knuckle, pinky_knuckle, hand_name
        )
        
        transformation_matrix = np.array([[1, 0, 0], [0, -1, 0], [0, 0, -1]])
        rotation_matrix = np.array(hand_dir_frame[1:])
        transformed_rotation_matrix = transformation_matrix @ rotation_matrix
        
        projected_coords = np.zeros_like(translated_coords)
        for finger_idx in range(5):
            projected_coords[finger_idx] = (
                translated_coords[finger_idx] @ transformed_rotation_matrix.T
            )
        
        projected_coords = projected_coords * 100.0
        
        return projected_coords, hand_dir_frame

    def _operate_hand(self, hand_name, transformed_hand_coords):
        """ë¡œë´‡ ì† ì œì–´"""
        if hand_name not in self.hands:
            return
        
        try:
            t_start = time.perf_counter()
            
            # ì´ë™í‰ê·  í•„í„° ì ìš©
            transformed_hand_coords = moving_average(
                transformed_hand_coords,
                self.coord_moving_average_queues[hand_name],
                self.moving_average_limit,
            )
            
            # ë¡œë´‡ ì œì–´ ëª…ë ¹
            self.hands[hand_name].step(transformed_hand_coords)
            
            # íƒ€ì´ë° ê¸°ë¡
            self._timing_stats['robot'].append(
                (time.perf_counter() - t_start) * 1000
            )
            
        except Exception as e:
            if self.debug:
                print(f"[WARNING] {hand_name} ì† ì²˜ë¦¬ ì‹¤íŒ¨: {e}")

    def _process_frame(self, img):
        """í”„ë ˆì„ ì²˜ë¦¬ ë° ì† ê²€ì¶œ"""
        t_start = time.perf_counter()
        
        # MediaPipeë¡œ ì† ê²€ì¶œ
        hands, img = self.detector.findHands(img, draw=True, flipType=True)
        
        # MediaPipe íƒ€ì´ë° ê¸°ë¡
        self._timing_stats['mediapipe'].append(
            (time.perf_counter() - t_start) * 1000
        )
        
        hand_data = {}
        
        if hands:
            for hand in hands:
                mp_hand_type = hand["type"].lower()
                
                # ê±°ìš¸ ëª¨ë“œ ë³´ì •
                if mp_hand_type == "left":
                    hand_type = "right"
                else:
                    hand_type = "left"
                
                lmList = hand["lmList"]
                finger_keypoints = self._mediapipe_to_finger_keypoints(lmList)
                finger_keypoints = finger_keypoints / 1000.0
                
                hand_data[hand_type] = finger_keypoints
        
        return hand_data, img

    def _run_robots(self):
        """ë©”ì¸ ì œì–´ ë£¨í”„"""
        # ì›¹ìº  í”„ë ˆì„ ì½ê¸°
        t_webcam = time.perf_counter()
        success, img = self.cap.read()
        self._timing_stats['webcam'].append(
            (time.perf_counter() - t_webcam) * 1000
        )
        
        if not success:
            return None
        
        # ğŸ†• í”„ë ˆì„ ìŠ¤í‚µ ì²˜ë¦¬
        self.frame_counter += 1
        if self.skip_frames > 0 and self.frame_counter % (self.skip_frames + 1) != 0:
            return img  # ì²˜ë¦¬ ì—†ì´ í™”ë©´ë§Œ ë°˜í™˜
        
        # ì† ê²€ì¶œ ë° ì²˜ë¦¬
        hand_data, img = self._process_frame(img)
        
        # ì¢Œí‘œ ë³€í™˜ ë° ë¡œë´‡ ì œì–´
        t_transform = time.perf_counter()
        
        for hand_name in self.hand_names:
            if hand_name in hand_data:
                transformed_hand_coords, _ = self.transform_keypoints(
                    hand_data[hand_name], hand_name
                )
                self._operate_hand(hand_name, transformed_hand_coords)
        
        self._timing_stats['transform'].append(
            (time.perf_counter() - t_transform) * 1000
        )
        
        return img

    def _draw_stats(self, img):
        """ì„±ëŠ¥ í†µê³„ í™”ë©´ í‘œì‹œ"""
        # FPS í‘œì‹œ
        fps = self.timer.actual_fps
        cv2.putText(
            img, f"FPS: {fps:.1f}", (10, 30),
            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2
        )
        
        # ë£¨í”„ ì‹œê°„ í‘œì‹œ
        loop_ms = self.timer.loop_time_ms
        cv2.putText(
            img, f"Loop: {loop_ms:.1f}ms", (10, 60),
            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2
        )
        
        # ì œì–´ ëŒ€ìƒ í‘œì‹œ
        status_text = "Hands: " + ", ".join(
            [h.upper() for h in self.hand_names if h in self.hands]
        )
        cv2.putText(
            img, status_text, (10, 90),
            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2
        )
        
        # ìƒì„¸ íƒ€ì´ë° (ë””ë²„ê·¸ ëª¨ë“œ)
        if self.debug:
            y_offset = 120
            for name, times in self._timing_stats.items():
                if times:
                    avg_time = sum(times) / len(times)
                    cv2.putText(
                        img, f"{name}: {avg_time:.1f}ms",
                        (10, y_offset),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (200, 200, 200), 1
                    )
                    y_offset += 25
        
        return img

    def run(self):
        """ë©”ì¸ ì‹¤í–‰ ë£¨í”„"""
        self._init_hands()
        
        print("\n[INFO] í…”ë ˆì˜¤í¼ë ˆì´ì…˜ ì‹œì‘")
        print("[INFO] ì¢…ë£Œ: 'q' í‚¤")
        print("=" * 60)
        
        try:
            while True:
                self.timer.start_loop()
                
                # ë¡œë´‡ ì œì–´
                img = self._run_robots()
                
                if img is not None:
                    # í†µê³„ í‘œì‹œ
                    img = self._draw_stats(img)
                    cv2.imshow("WebCam Teleoperator - RUKA Hand (Optimized)", img)
                
                self.timer.end_loop()
                
                # ì¢…ë£Œ í‚¤
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    print("\n[INFO] ì‚¬ìš©ì ì¢…ë£Œ ìš”ì²­")
                    break
        
        except KeyboardInterrupt:
            print("\n[INFO] Ctrl+Cë¡œ ì¢…ë£Œ")
        
        finally:
            self._cleanup()

    def _cleanup(self):
        """ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        print("\n[INFO] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
        
        # ë¡œë´‡ í† í¬ ë¹„í™œì„±í™”
        for hand_name, hand_op in self.hands.items():
            try:
                print(f"  â†’ {hand_name.upper()} í† í¬ ë¹„í™œì„±í™”...")
                if hasattr(hand_op, 'controller') and hasattr(hand_op.controller, 'hand'):
                    hand_op.controller.hand.disable_torque()
                    print(f"    âœ“ {hand_name.upper()} í† í¬ ë¹„í™œì„±í™” ì™„ë£Œ")
            except Exception as e:
                print(f"    âœ— {hand_name.upper()} í† í¬ ë¹„í™œì„±í™” ì‹¤íŒ¨: {e}")
        
        # ì›¹ìº  í•´ì œ
        if self.cap.isOpened():
            self.cap.release()
            print("  âœ“ ì›¹ìº  í•´ì œ ì™„ë£Œ")
        
        # OpenCV ì°½ ë‹«ê¸°
        cv2.destroyAllWindows()
        print("  âœ“ OpenCV ì°½ ë‹«ê¸° ì™„ë£Œ")
        
        # ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥
        print("\n[ì„±ëŠ¥ ìš”ì•½]")
        for name, times in self._timing_stats.items():
            if times:
                avg_time = sum(times) / len(times)
                print(f"  - {name}: í‰ê·  {avg_time:.1f}ms")
        
        print(f"  - í‰ê·  FPS: {self.timer.actual_fps:.1f}")
        print("\n[INFO] ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        print("=" * 60)


# =============================================================================
# ë©”ì¸ ì‹¤í–‰
# =============================================================================

def main():
    """WebCam Teleoperator ì‹¤í–‰ (ìµœì í™” ë²„ì „)"""
    
    teleoperator = WebCamTeleoperator(
        camera_id=0,
        frequency=20,                   # 20Hz (í˜„ì‹¤ì  ëª©í‘œ)
        moving_average_limit=5,         # ì§§ì€ í•„í„°
        hands=["right"],                # ë‹¨ì¼ ì† (ì„±ëŠ¥â†‘)
        detection_confidence=0.5,       # ë‚®ì€ ì„ê³„ê°’ (ì†ë„â†‘)
        tracking_confidence=0.5,
        debug=False,                    # ë””ë²„ê·¸ OFF
        resolution=(640, 480),          # ì €í•´ìƒë„
        model_complexity=0,             # Lite ëª¨ë¸
        skip_frames=0,                  # í”„ë ˆì„ ìŠ¤í‚µ ì—†ìŒ
    )
    
    teleoperator.run()


if __name__ == "__main__":
    main()